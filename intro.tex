There is growing demand for firm-level data allowing detailed studies of firm dynamics. Recent examples include \textcite{NBERc0480} who use cross-country firm-level data to study average post-entry behavior of young firms. \textcite{10.1257/aer.20141280} use the Business Dynamics Statistics (BDS) to show the role of firm size in firm dynamics. However, such studies are made difficult due to the limited or restricted access to firm-level data.

Data on businesses collected by statistical agencies are challenging to protect. Many businesses have unique characteristics, and distributions of employment, sales, and profits are highly skewed. Attackers wishing to conduct identification attacks often have access to much more information than for any individual. It is easy to find examples of firms and establishments that are so dominant in their industry or location that they would be immediately identified if  data were publicly released that included their survey responses or administratively collected data. Finally, there are also greater financial incentives to identifying the particulars of some firms and their competitors.

As a consequence, most disclosure avoidance mechanisms  fail to strike an acceptable balance between usefulness and confidentiality protection. Detailed aggregate statistics by geography or detailed industry classes  are rare, public-use microdata on business are virtually inexistant,\footnote{See \citet{NBERw22095} and \citet{startupcartography} for an example of scraped, public-use microdata.} and access to confidential microdata can be burdensome. It is not uncommon that access to establishment microdata, if granted at all, is provided through data enclaves (Research Data Centers), at headquarters of statistical agencies, or some other limited means, under strict security conditions. These restrictions on data access reduce the growth of knowledge by increasing the cost to researchers of accessing the data.

Synthetic microdata have been proposed as a secure mechanism to publish microdata \citep{drechsler2008,RePEc:taf:japsta:v:39:y:2012:i:2:p:243-265,NAP11844,SJIAOS-2014c}, based on suggestions and methods first proposed by \citet{rubin93} and \citet{little93}. Such data are  part of a broader discussion of how  to provide improved access to such datasets to researchers  \citep{Bender2009,Vilhuber2013,AbowdLane2004,AbowdSchmutte_BPEA2015}.\footnote{
	For a recent overview of some, see \citet{VilhuberAbowdReiter:Synthetic:SJIAOS:2016}. See \citet{dre:2011} for a review of the theory and applications of the synthetic data methodology.
	Other access methods include secure data enclaves (e.g., research data centers of the U.S. Federal Statistical System, of the  German Federal Employment Agency, others), and  remote submission system systems. We will comment on the latter in the conclusion. \todo{Make sure, we really do this in the conclusion or delete the last sentence.} }
For business data, synthetic business microdata were released in the United States \citep{KinneyEtAl2011} and in Germany  \citep{RePEc:iab:iabfme:201101_de} in 2011. The former dataset, called \ac{SynLBD}, was  released to an easily web-accessible computing environment \citep{AbowdVilhuber2010}, and combined with a validation mechanism.  By making disclosable synthetic microdata available through a remotely accessible data server, combined with a validation server, the SynLBD approach alleviates some of the access restrictions associated with economic data. The approach is mutually beneficial to both agency and researchers. Researchers can access public use servers at little or no cost, and can later validate their model-based inferences on the full confidential microdata. Details about the modeling strategies used for the \SynLBD can be found in  %
%\citet[henceforth KRRMJA]{KinneyEtAl2011} 
\citet{KinneyEtAl2011} 
and \citet{RePEc:cen:tnotes:11-01}.


In this article, we document an experiment to create analytically valid synthetic data, using the exact same model and methods previously used to create the \ac{SynLBD}, but applied to data from two different countries: Canada (\ac{LEAP}) and Germany (\ac{BHP}). We describe all three countries' data in Section~\ref{sec:data}. 


In Canada, the Canadian Center for Data Development and Economic Research (CDER) was created in 2011 to allow Statistics Canada to make better use of its business data holdings, without compromising security. Secure access  to business microdata for approved analytical research projects is done through a physical facility located in Statistics Canadaâ€™s headquarters. 

CDER implements many risks mitigation measures to alleviate the security risks specific to micro-level business data including limits on tabular outputs, centralized vetting, monitoring of programs logs. Access to the data is done through a Statistics Canada designed interface in which actual observations cannot be viewed. But the most significant barrier to access remains the  cost of traveling to Ottawa.

The Institute for Employment Research (IAB) in Germany also strictly regulates the access to its business data. All business data can  be accessed exclusively onsite at the research data center (RDC) and only after the research proposal has been approved by the Federal Ministry of Labour and Social Affairs. All output is carefully checked by staff at the RDC and only cleared output can be removed  from the RDC. 

The experiment aims not so much at finding the \textit{best} synthetic data method for each file, but rather to assess the effectiveness of using a `pre-packaged' method to cost-effectively generate synthetic data. In particular, while we could have used newer implementations of methods combined with a pre-defined or automated model \citep{JSSv074i11,Raab_Nowok_Dibben_2018}, we chose to use the exact SAS code used to create the original \ac{SynLBD}. A brief synopsis of the  method, and any adjustments we made to take into account structural data differences, are described in Section~\ref{sec:methodology}.


%\todo{do modify according to what was exactly done in the respective cases of Canada and Germany}

We verify the analytical validity of the synthetic data files so created along a variety of measures. First, we show how well average firm characteristics (gross employment, total payroll) in the synthetic data  match those from the original data. We also consider how well the synthetic data replicates various measures of firm dynamics (entry and exit rates) and job flows (job creation and destruction rate). Second, we compute an aggregate measure of distributional fit between the synthetic and confidential data ($pMSE$). Finally, we estimates for models of economic growth, and assess how these estimates vary between both data sets using dynamic panel data models. 

To assess how protective the newly created synthetic database is, we estimate the probability that the synthetic first year equals the true first year given the synthetic fist year.

% and find that those probabilities are quite low except for the first year included in the respective databases. 
%The probability for the first year is higher because of censoring and lack of previous information.

The rest of the paper is organized as follows. Section 2 describes the different data sources and summarizes which steps were taken to harmonize the datasets prior to the actual synthesis. Section 3 provides some background on the synthesis methods, limitations in the applications, and a discussion of some of the measures, which are used in Section 4 to measure the analytical validity of the generated datasets. Preliminary results regarding the achieved level of protection are included in Section 5. The paper concludes with...
\todo{Write something about conclusion}
