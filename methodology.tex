%The US SynLBD was released in 2010 to the Cornell SDS. The Census Bureauâ€™s Disclosure Review Board (DRB), as well as the Internal Revenue Service (IRS), classified SynLBD as public-use, but access is controlled due to concerns about the quality of the data. There are no disclosure concerns but researchers are cautioned not to trust results as if they were created by a traditional public-use file without going through the validation process. For similar reasons, the preparation of tabular data based on the synthetic data is strongly discouraged, and are not validated. Nevertheless, the synthetic data are of much easier access than the confidential data.


The Synthetic LBD is derived from the LBD as a partially synthetic database with analytic validity, by synthesizing the life-span of establishments, as well as the evolution of their employment, conditional on industry. Geography is not synthesized, but is suppressed from the released file \citep{RePEc:cen:tnotes:11-01}. The current version, is based on the Standard Industrial Classification (SIC) and extends through 2000. \citet{RePEc:cen:wpaper:14-12} describes efforts to create a new version of the Synthetic LBD, using a longer time  series (through 2010) and newer industry coding (NAICS), while also adjusting and extending the models for  improved  analytic validity and  the imputation of additional variables. In this paper, we refer to and re-use the older methodology, which we will call \SynLBD. Our emphasis is on the comparability of results obtained for a given methodology across the various applications.
  

\deleted{We can currently distinguish between two methods to create synthetic data.}\todo{Since we do not describe the two approaches, I would suggest dropping this sentence.} The general approach to data synthesis is to generate a joint posterior predictive distribution of $Y|X$ where $Y$ are variables to be synthesized and $X$ are unsynthesized variables. The synthetic data are generated by sampling new values from this distribution. In \SynLBD, variables are synthesized in a sequential fashion, with categorical variables being generally processed first using a variant of Dirichlet-Multinomial models. Continuous variables are then synthesized using a normal linear regression model with kernel density-based transformation \citep{WOODCOCK20094228}.\footnote{\textcite{RePEc:cen:wpaper:14-12} shift  to a Classification and Regression Trees (CART) model with Bayesian bootstrap. } \SynLBD{} is implemented in SAS\texttrademark, which is frequently used in national statistical offices.

To evaluate whether synthetic data algorithms developed in the U.S. can be adapted to generate similar synthetic data for other countries, \textcite{RePEc:cen:wpaper:14-13} implement \SynLBD{} to the German Longitudinal Business Database (GLBD). In this paper, we extend the analysis from the earlier paper, and extend the application to the Canadian context (SynLEAP). 


\subsection{Harmonizing and Preprocessing}

In all countries, the underlying data provides annual measures. However, \SynLBD{} assumes a longitudinal (wide) structure of the dataset, with invariant industry (and location). In all cases, the modal industry is chosen to represent the entity's industrial activity. 

Further adjustments made to the \ac{BHP} for this project, include estimating full-year payroll, creating time-consistent geographic information, and applying employment flow methods \citep{RePEc:iab:iabfme:201006_en} to adjust for spurious births and deaths in establishment identifiers. \citet{SJIAOS-2014b} provide a detailed description of the steps taken to harmonize the input data. 

\subsection{Limitations}

In both cases, we encountered various technical and data-driven limitations. In all countries, the first year and last year is occasionally problematic, and were dropped. Furthermore, in all countries, the synthesis of certain industries failed to complete. In both Canada and the US, this number is less than 10. In Canada, they account for about 7 percent of the total number of observations (see Table \ref{tab:Synthesized_observations} in the Appendix).

In the German case, our experiments were limited to only a handful of industries, due to a combination of time and software availability factors. The results should still be considered preliminary. In both countries, as outlined in Section~\ref{sec:data}, there are subtle but potentially important differences in the various variable definitions. Industry coding differs across all three countries, and the level of detail in each of the industry codings may affect the success and precision of the synthesis.\footnote{\textcite{StatisticsCanada1991}, when comparing the 1987 US \ac{SIC} to the 1980 Canadian \ac{SIC},  already pointed out that the degree of specialization, the organization of production, and the size of the respective markets differed. Thus, the density of establishments within each of the chosen categories is likely to affect the quality of the synthesis.} 

Furthermore, due to the nature of the underlying data, entities are establishments in Germany and the US, but employers in Canada. \SynLBD{} should work on any level of entity aggregation (see \citet{RePEc:cen:wpaper:14-12} for an application to hierarchical firm data with both firm/employer and establishment level imputation). However, it may yet again affect the observed density of the data within industry-year categories, and therefore the overall comparability. 

Both the German and the Canadian data experience some level of industry coding change, which may affect the classification of some entities. 

Finally, due to a feature of \SynLBD{} that we do not fully understand, the last year of the data generally was of poor quality. For some industry-country pairs, this also happened in the first year. We dropped those observations. 

\subsection{Measuring outcomes}

In order to assess the outcomes of the experiment, we inspect analytical validity by various measures, the extent of confidentiality protection, and the utility for model development. To check analytical validity, we compare basic univariate time series between the synthetic and confidential data (employment, entity entry and exit rates, job creation and destruction rates), and the distribution of entities (firms and establishment, depending on country),  employment, and payroll across time by industry. 

To provide a more comprehensive measure of  quality of the synthetic data relative to the confidential data, we compute the $pMSE$ \parencite[propensity score mean-squared error,][]{Woo_Reiter_Oganian_Karr_2009,SnokeSlavkovic2018,Snoke_RSSA2018}: the mean-squared error of the predicted probabilities (i.e., propensity scores) for those two databases. Specifically, $pMSE$ is a metric to assess how well we are able to discern the high distributional similarity between synthetic data and confidential data. 

We follow  \textcite{SnokeSlavkovic2018} to calculate the $pMSE$. This method involved the following steps: 
\todo{This notation clashes with the earlier one. We need to consolidate notation. I've replaced "it" with "et" (entity) reserving the "i" for industry}
\begin{enumerate}
    \item Append the $n_1$ rows of the confidential database $X$ to the $n_2$ rows of the synthetic database $X^s$ to create $X^{comb}$ with $N=n_1 + n_2$ rows.
    \item Create a variable $I_{et}$ denoting membership of an observation for entity $e$ in the component databases,  $I_{et}=\{1: X^{comb}_{et} \in X^s\}$. $I_{et}$ takes on values of $1$ for the synthetic database and $0$ for the confidential database. 
    \item Fit the following model to predict $I$
    \begin{eqnarray}	
        I_{et} & = &\alpha + \beta_{1} Emp_{et} + \beta_{2} Pay_{et} + Age_{et}^{T}\beta_{3} + \lambda_t + \alpha_i + \epsilon_{et} \label{pMSE}
     \end{eqnarray}
         where $Emp_{et}$ is  log employment  of entity $e$ in year $t$, $Pay_{et}$ is  log payroll of entity $e$ in year $t$, $Age_{et}$ is a vector of age classes of entity $e$ in year $t$, $\lambda_t$ is a year fixed effect, $\alpha_i$ is an unobserved time-invariant industry-specific effect, and $\epsilon_{et}$ is the disturbance term of entity $e$ in year $t$. 
    \item Calculate the predicted probabilities, $\hat{I}_{it}$
    \item Compute the $pMSE=\frac{1}{N}\sum_{i=1}^N(\hat{p}_i - n_1/N)^2$
\end{enumerate}
If $n_1 = n_2$, $pMSE$ = 0 means every $\hat{p}_i = 0.5$, and the two databases are distributionally indistinguishable and we can conclude that the analytical validity is high, as the variables included in the propensity model cannot predict the data source.


For a more complex assessment, we compute a dynamic panel data model of economic (employment) growth on each dataset. We then assess fit of the model in two ways. \todo{What is the other assessment you had in mind?} First, analytic validity --- statistical precision --- can be assessed using confidence interval overlap measures   \citep{tas2006}. \todo{Do we compute them? If not, we should drop this. If we want we could include a short discussion why CIO is not a helpful measure here}
We compute the \emph{interval overlap measure} $J_{k,m}$ for parameter $k$ in model $m$. Consider the overlap of confidence intervals $(L,U)$ for $\beta_{k,m}$ (estimated from the confidential data) and $(L^{*},U^{*})$ for $\beta_{k,m}^*$ (from the synthetic data). Let $L^{over} = \max (L,L^{*} )$ and $U^{over} = \min (U,U^{*})$. Then the average overlap in confidence intervals is
$$
J_{k,m}^{*} = \frac{1}{2} \left [ \frac{U^{over} - L^{over}}{U-L} + \frac{U^{over} - L^{over}}{U^*-L ^*}        \right ]
$$
We can also compute an overall score by  averaging $J_{k,m}^{*}$ over all  parameters. 